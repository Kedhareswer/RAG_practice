# RAG Q&A Application - Next.js + Transformer.js

A powerful Retrieval Augmented Generation (R&A) chatbot with persistent document storage, built with Next.js, TypeScript, and Transformer.js. Features client-side embeddings, multi-format document support, and a modern ChatGPT-like interface.

A powerful Retrieval Augmented Generation (RAG) Q&A chatbot built with Next.js, TypeScript, and Transformer.js. This application runs entirely standalone with client-side embeddings and supports multiple document formats.

## âœ¨ Key Features

### ğŸ—‚ï¸ Document Processing
- ğŸ“„ **Multi-format Support**: PDF, DOCX, TXT, CSV, Excel, JSON, Markdown, Images (JPG, PNG)
- ğŸ”„ **Persistent Storage**: Documents and embeddings saved between sessions
- ğŸ” **Advanced Search**: Semantic search with cosine similarity
- ğŸ”„ **Auto-save**: All changes automatically persisted

### ğŸ¤– AI & ML
- ğŸ§  **Local Embeddings**: Transformer.js with all-MiniLM-L6-v2
- ğŸ’¡ **Smart Context**: Retrieval Augmented Generation (RAG)
- ğŸŒ **LLM Integration**: Google Gemini 2.0 Flash API
- âš¡ **Batch Processing**: Efficient embedding generation

### ğŸ¨ Modern Interface
- ğŸ’¬ **ChatGPT-like UI**: Familiar messaging interface
- ğŸŒ“ **Dark Theme**: Easy on the eyes
- ğŸ“± **Responsive Design**: Works on all devices
- ğŸ­ **Collapsible Sidebars**: Maximize your workspace

## ğŸ› ï¸ Tech Stack

### Core Technologies
- **Framework**: Next.js 14 (App Router)
- **Language**: TypeScript
- **Styling**: Tailwind CSS + Shadcn UI
- **Icons**: Lucide React

### AI & ML
- **Embeddings**: Transformer.js (@xenova/transformers)
- **Model**: sentence-transformers/all-MiniLM-L6-v2
- **LLM**: Google Gemini 2.0 Flash

### Document Processing
- **PDF**: pdf-parse
- **DOCX**: mammoth
- **Excel/CSV**: xlsx
- **Images**: tesseract.js (OCR)
- **JSON/Markdown**: Native parsing

### Storage
- **Vector Store**: In-memory with disk persistence
- **Cache**: File system based
- **Session Management**: Automatic state persistence

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ (LTS recommended)
- Google Gemini API key ([Get one here](https://makersuite.google.com/app/apikey))
- npm or yarn package manager

### Installation

1. Clone the repository and navigate to the project directory:
```bash
git clone [your-repo-url]
cd RAG/Application
```

2. Install dependencies:
```bash
npm install
# or
yarn install
```

3. Set up environment variables:
```bash
cp .env.local.example .env.local
```

4. Add your Google API key to `.env.local` (or enter it in the UI):
```
GOOGLE_API_KEY=your_api_key_here
```

5. Start the development server:
```bash
npm run dev
# or
yarn dev
```

6. Open [http://localhost:3000](http://localhost:3000) in your browser

## ğŸ“– User Guide

### ğŸ Getting Started
1. **Enter your API Key**
   - Paste your Google Gemini API key in the top bar
   - Or set it in `.env.local` as `GOOGLE_API_KEY`
   - Get your key from [Google AI Studio](https://makersuite.google.com/app/apikey)

2. **Upload Documents**
   - Click "Upload Documents" or drag & drop files
   - Supports multiple files in one go
   - Supported formats: PDF, DOCX, TXT, CSV, XLSX, JSON, MD, JPG, PNG
   - Documents are automatically processed and saved

3. **Chat with Your Documents**
   - Type your question in the chat input
   - Press Enter or click the send button
   - View AI-generated answers with source citations
   - Conversation history is automatically saved

### ğŸ”„ Document Persistence
- Uploaded documents and their embeddings are automatically saved
- Data persists across page refreshes and server restarts
- No need to re-upload documents
- Clear all data anytime from the settings

### âš™ï¸ Settings & Configuration
- **Model Settings**: Adjust temperature, max tokens
- **RAG Parameters**: Configure chunk size, overlap, and top-K results
- **System Prompt**: Customize the AI's behavior
- **Theme**: Toggle between light and dark mode

## ğŸ—ï¸ Architecture Overview

### Frontend Components
- **Left Sidebar**: Document management and chat history
- **Right Sidebar**: Settings and configuration
- **Chat Interface**: Message display and input
- **File Upload**: Drag & drop with progress tracking
- **Settings Panel**: Model and RAG configuration

### Backend API Routes
- **`/api/upload`**: 
  - Handles document uploads and processing
  - Supports batch processing of multiple files
  - Generates and stores embeddings
  - Auto-saves to persistent storage
  
- **`/api/query`**:
  - Processes natural language queries
  - Performs semantic search
  - Generates contextual responses
  - Returns sources and confidence scores
  
- **`/api/vector-store`**:
  - Manages document persistence
  - Provides status and metrics
  - Handles clearing of stored data

## ğŸ§© Core Components

### `documentLoader.ts`
- **DocumentLoader**: Unified interface for all document types
- **RecursiveCharacterTextSplitter**: Intelligent text chunking with overlap
- **Format Support**:
  - PDF: Full text extraction with metadata
  - DOCX: Preserves formatting and structure
  - Images: OCR with Tesseract.js
  - Spreadsheets: Tabular data extraction
  - JSON: Structured data parsing

### `embeddings.ts`
- **Transformer.js Integration**: Local embedding generation
- **Batch Processing**: Optimized for performance
- **Vector Operations**:
  - Cosine similarity
  - L2 normalization
  - Batch processing
- **Caching**: Redundant computation prevention

### `vectorStore.ts`
- **In-Memory Store**: Fast vector search
- **Persistence Layer**:
  - Automatic saving to disk
  - Loading on startup
  - Versioning support
- **Search Features**:
  - Top-K nearest neighbors
  - Similarity thresholding
  - Metadata filtering

### `gemini.ts`
- **API Client**: Handles all Gemini API communication
- **Prompt Engineering**:
  - Context window management
  - System message templating
  - Response formatting
- **Error Handling**:
  - Rate limiting
  - Timeouts
  - Fallback responses

## ğŸ“ Project Structure

```
Application/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ upload/              # Document processing
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ route.ts         
â”‚   â”‚   â”‚   â”œâ”€â”€ query/               # RAG query endpoint
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ route.ts         
â”‚   â”‚   â”‚   â””â”€â”€ vector-store/        # Persistence management
â”‚   â”‚   â”‚       â””â”€â”€ route.ts         
â”‚   â”‚   â”œâ”€â”€ page.tsx                 # Main application page
â”‚   â”‚   â”œâ”€â”€ layout.tsx               # Root layout
â”‚   â”‚   â””â”€â”€ globals.css              # Global styles
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ui/                      # Shadcn UI components
â”‚   â”‚   â”œâ”€â”€ FileUpload.tsx           # File upload interface
â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx        # Chat UI components
â”‚   â”‚   â””â”€â”€ LeftSidebar.tsx          # Navigation and documents
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ embeddings.ts            # Text embeddings
â”‚   â”‚   â”œâ”€â”€ vectorStore.ts           # Vector database
â”‚   â”‚   â”œâ”€â”€ documentLoader.ts        # Document processing
â”‚   â”‚   â””â”€â”€ gemini.ts                # LLM integration
â”‚   â””â”€â”€ types/                       # TypeScript types
â”œâ”€â”€ public/                          # Static assets
â”œâ”€â”€ .cache/                          # Persistent storage
â”‚   â””â”€â”€ vector-store.json            # Document embeddings
â”œâ”€â”€ .env.local                       # Environment variables
â”œâ”€â”€ package.json                     # Dependencies
â”œâ”€â”€ tsconfig.json                    # TypeScript config
â”œâ”€â”€ tailwind.config.ts               # Tailwind CSS config
â”œâ”€â”€ next.config.mjs                  # Next.js config
â””â”€â”€ README.md                        # This file
```
```

## ğŸ”„ How It Works

### Document Processing Pipeline
1. **Upload & Extraction**
   - Files uploaded via drag & drop or file picker
   - Automatic format detection and processing
   - Text extraction with format-specific parsers
   - OCR for images using Tesseract.js

2. **Text Processing**
   - Smart chunking with configurable size/overlap
   - Metadata extraction and preservation
   - Language detection and normalization

3. **Embedding Generation**
   - Local embedding model (all-MiniLM-L6-v2)
   - Batch processing for efficiency
   - Vector normalization
   - Automatic persistence to disk

4. **Query Processing**
   - Natural language query understanding
   - Semantic search with cosine similarity
   - Context-aware response generation
   - Source attribution and citations

5. **Response Generation**
   - Context-aware prompt construction
   - Multi-turn conversation support
   - Confidence scoring
   - Fallback handling

## ğŸš€ Performance & Optimization

### Optimized Processing
- **Batch Processing**: Parallel embedding generation
- **Smart Chunking**: 1000-character chunks with 200-character overlap
- **Efficient Storage**: Compressed vector storage
- **Lazy Loading**: Models loaded on demand

### Caching Strategy
- **Embedding Cache**: Avoids redundant computations
- **Browser Storage**: Local state persistence
- **File System**: Persistent document storage
- **Memory Management**: Automatic cleanup of old data
- **Lazy Loading**: Transformer.js model loaded on first use
- **Streaming**: Future enhancement for real-time responses

## Limitations

- **Session-based**: Vector store resets on server restart
- **Memory**: Large document sets may require optimization
- **Single User**: Not designed for multi-user concurrent access
- **API Key**: Required for each query (not stored server-side)

## Future Enhancements

- [ ] Persistent vector storage (PostgreSQL with pgvector)
- [ ] User authentication and document management
- [ ] Streaming responses
- [ ] Multiple embedding models
- [ ] Document preview and highlighting
- [ ] Export conversation history
- [ ] Advanced filtering and search
- [ ] Multi-language support

## Troubleshooting

### "Failed to load embedding model"
- Check internet connection (model downloads from Hugging Face)
- Ensure sufficient disk space for model cache
- Try clearing Next.js cache: `rm -rf .next`

### "Invalid Google API key"
- Verify key from [Google AI Studio](https://makersuite.google.com/app/apikey)
- Check API is enabled for your project
- Ensure no extra spaces in key

### "Failed to load PDF"
- Ensure PDF is not password-protected
- Check file is not corrupted
- Try re-saving PDF from another application

### Upload hangs
- Check file size (large files take longer)
- Monitor browser console for errors
- Ensure sufficient server memory

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

MIT

## Acknowledgments

- [Transformer.js](https://github.com/xenova/transformers.js) by Xenova
- [Google Gemini](https://ai.google.dev/) for LLM capabilities
- [Next.js](https://nextjs.org/) team for the amazing framework
- [Hugging Face](https://huggingface.co/) for the embedding model
